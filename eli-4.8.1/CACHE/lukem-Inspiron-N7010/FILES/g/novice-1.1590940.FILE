This is Info file novice, produced by Makeinfo-1.43 from the input
file /home/lukem/Dropbox/CAS/eli-4.8.1/Eli/pkg/info/tnf/novice.tnf.


File: novice,  Node: Top,  Up: (dir)

   $Revision: 3.13 $

   A text processor is a program that takes a sequence of characters
as input, computes some set of values based on that sequence, and then
carries out some action determined by the computed values.  A desk
calculator program is therefore a text processor, as is a Pascal
compiler and the input subsystem of a transaction processor.

   The Eli system creates executable text processing programs from
specifications.  A user provides Eli with specifications that describe
a particular text processing problem, and Eli creates a program to
solve that problem.  By making simple requests of Eli, the user can
test the generated program, obtain an executable copy, or obtain a
directory containing a source copy.

* Menu:

* Overview::		How Eli creates a text processing program
* Specifications::	  Ways to describe text processing
* Products::		  Ways to describe derived objects
* Interactive::		  Ways to request product manufacture
* Escape::		  Ways to invoke unix commands

* Example::		Illustration of Eli usage
* Problem::		  Statement of the problem to be solved
* Structure::		  Specifying the desired phrase structure
* Atoms::		  Nonliteral character sequences and comments
* Entities::		  Managing source text definitions
* Generation::		  Creating structured output text

			Exercises involving the Eli example
* tskex::		  Getting the sample specification
* parex::		  How to verify parsability of a grammar
* procex::		  How to generate a processor
* symbex::		  How to extract a processor from Eli
* debugex::		  How to debug Eli-generated C code

* Strategies::		Ways to alter Eli's behavior
* Cache::		  Hints on Cache Management
* Session::		  Hints on Session Management

* Documentation::	How to access system documentation

* Index::		Index to this manual.


File: novice,  Node: Overview,  Next: Example,  Up: Top

How Eli Creates a Text Processing Program
*****************************************

   The program generated by Eli reads a file containing the text,
examining it character-by-character.  Character sequences are
recognized as significant units or discarded, and relationships among
the sequences are used to build a tree that reflects the structure of
the text.  Computations are then carried out over the tree, and the
results of these computations determine the processor's output.  Thus
Eli assumes that the original text processing problem is decomposed
into the problems of determining which character sequences are
significant and which should be discarded, what tree structure should
be imposed on significant sequences, what computations should be
carried out over the resulting tree, and how the computed values
should be encoded and output.

* Menu:

* Subproblems::		How to decompose a text processing problem
* Specifications::	Descriptive mechanisms known to Eli
* Products::		Common products that Eli can manufacture
* Interactive::		How to request product manufacture
* Escape::		How to invoke unix commands


File: novice,  Node: Subproblems,  Next: Specifications,  Up: Overview

How to Decompose a Text Processing Problem
==========================================

   There is considerable variability in the specific decompositions
for particular text processing problems.  For example, one subproblem
of the compilation problem for many programming languages is *overload
resolution*: how to decide that (say) a particular `+' operator means
integer addition instead of real addition.  Overload resolution would
probably not be a subproblem of the problem of creating a PostScript
version of a musical score from a description of the desired notes. 
This section briefly reviews five major subproblems common to a wide
range of problems:

* Menu:

* Syntactic analysis::	Determining the structure of an input text
* Lexical analysis::	Recognizing character sequences
* Attribution::		Computing values over trees
* Property storage::	Maintaining information about entities
* Text generation::	Producing structured output


File: novice,  Node: Syntactic analysis,  Next: Lexical analysis,  Up: Subproblems

Determining the structure of an input text
..........................................

   "Syntactic analysis" determines the "phrase structure" of the input
text.  The phrase structure is described to Eli by a "context-free
grammar".  Here is a context-free grammar describing the structure of
a geographical position (*note Context-Free Grammars and Parsing:
(syntax)Phrases.):

     Position: Latitude Longitude .
     Latitude: NS Coordinate .
     Longitude: EW Coordinate .
     NS: 'N' / 'S' .
     EW: 'E' / 'W' .
     Coordinate: Integer Float .

   This grammar has eight symbols (`Position', `Latitude', `Longitude',
`NS', `EW', `Coordinate' `Integer' and `Float'), four literals (`'N'',
`'S'', `'E'' and `'W'') and eight rules (`x: y / z .' is an
abbreviation for the two rules `x: y .' and `x: z .').  Two of the
symbols, `Integer' and `Float', are not defined by the grammar.  One
of the symbols, `Position', is not used in the definition of any other
symbol.

   Symbols that are not defined by the grammar are called "terminal"
symbols; those defined by the grammar are called "nonterminal" symbols. 
The (unique) symbol not used in the definition of any other symbol is
called the "axiom" of the grammar.

   The entire input text is called a "sentence", and corresponds to
the axiom.  Thus the input text `N41 58.8 W087 54.3' is a sentence
corresponding to `Position'.  A "phrase" is a portion of the sentence
corresponding to a nonterminal symbol of the grammar.  For example,
`N41 58.8' is a phrase corresponding to `Latitude', and `087 54.3' is
a phrase corresponding to `Coordinate'.  `54' and `58.8 W087' are
*not* phrases because they do not correspond to any symbols.  (`54' is
a part of the phrase `087 54.3' corresponding to `Coordinate' and
`58.8 W087' is made up of part of the phrase corresponding to
`Latitude' and part of the phrase corresponding to `Longitude'.)


File: novice,  Node: Lexical analysis,  Next: Attribution,  Prev: Syntactic analysis,  Up: Subproblems

Recognizing character sequences
...............................

   "Lexical analysis" is the process that examines the source program
text, retaining significant character sequences and discarding those
that are not significant.  A character sequence is significant if it
corresponds to a literal in the grammar or to a terminal symbol.  In
the sentence `N41 58.8 W087 54.3', the significant character sequences
are `N', `41', `58.8', `W', `087' and `54.3'.  The spaces separating
the numbers of a `Coordinate' and preceding the `Longitude' are not
significant.

   Eli obtains information about character sequences that correspond
to literals directly from the grammar.  The user must, however,
provide descriptions of the character sequences corresponding to each
terminal symbol.  Those descriptions determine the *form* of the
character sequences, but not their *content*.  For example, the
character sequences corresponding to the terminal symbol `Integer'
might be described as sequences of one or more decimal digits, and
those corresponding to the terminal symbol `Float' might be described
as pairs of such sequences separated by a dot (*note Regular
Expressions: (lex)Regular expressions.):

     Integer:  $[0-9]+
     Float:    $[0-9]+"."[0-9]+


File: novice,  Node: Attribution,  Next: Property storage,  Prev: Lexical analysis,  Up: Subproblems

Computing values over trees
...........................

   Computations may be specified over a tree that reflects the phrase
structure of a sentence.  That tree has one node corresponding to each
phrase, with the root corresponding to the sentence.  For example, the
tree that reflects the structure of the sentence `N41 58.8 W087 54.3'
has a node corresponding to the `Latitude' phrase `N41 58.8'.  Children
of a node correspond to the immediate component phrases of the phrase
corresponding to that node.  Thus the children of the the node
corresponding to the `Latitude' phrase `N41 58.8' would correspond to
the phrases `N' and `41 58.8', because the immediate components of the
`Latitude' phrase `N41 58.8' are an `NS' phrase (`N') and a
`Coordinate' phrase (`41 58.8').

   One or more values, called "attributes", may be associated with
each tree node.  Computations over the tree may involve only attribute
access, C constants, and function application.  Here is an example:

     RULE DegMin: Coordinate ::= Integer Float
     COMPUTE
       Coordinate.minutes=Minutes(Integer, Float);
     END;

According to the rule `DegMin', `Coordinate' has a `minutes' attribute
attached to it.  The `minutes' attribute of `Coordinate' is computed
by applying the function `Minutes' to the values representing
`Integer' and `Float', but how are those values obtained?  Clearly
they must depend on the character sequences corresponding to these
terminal symbols.

   A single integer value can be used to represent any terminal symbol. 
That value is determined by a "token processor" whose name is attached
to the definition of the character sequences corresponding to the
symbol, enclosed in brackets (*note Token Processors: (lex)Token
Processors.):

     Integer:  $[0-9]+           [mkstr]
     Float:    $[0-9]+"."[0-9]+  [mkstr]

   The processor `mkstr' is a library routine that stores the
character sequence in an array and yields the sequence's index. 
`Minutes' can then use the index values to obtain the stored strings,
convert them to numbers, and perform the necessary computation.


File: novice,  Node: Property storage,  Next: Text generation,  Prev: Attribution,  Up: Subproblems

Maintaining information about entities
......................................

   Often an input text describes some set of "entities" and the
relationships among them.  For example, a program in a conventional
language may describe some set of constants, variables, types and
procedures, and how these entities are related in the execution of an
algorithm.  Entities may be defined by one part of the input text and
used by another.  It is therefore necessary for computations over the
tree representing the phrase structure of a sentence to be able to
refer to entities and their properties at arbitrary points.  Eli
provides a "definition table" to meet this requirement (*note
Definition Table Design Criteria: (deftbl)Criteria.).

   Each entity can be represented by a unique "definition table key",
which allows access to arbitrary information about that entity.  The
Eli user specifies the information that might be stored, and possibly a
set of "query" and "update" operations for that information.  (Eli
provides a standard query operation and a standard update operation
that suffice for most purposes.)

   Library modules are available for associating unique definition
table keys with identifiers according to the scope rules of the input
text, and for maintaining various kinds of information about entities. 
Definition table keys themselves can be stored as attributes, compared
for equality, passed to query and update routines, and accessed either
directly or remotely.  A distinguished value, `NoKey', represents the
absence of a definition table key.


File: novice,  Node: Text generation,  Prev: Property storage,  Up: Subproblems

Producing structured output
...........................

   Output may be derived from arbitrary information in the input text. 
The elements of the output may be arranged in arbitrary ways based on
computations over the tree representing the phrase structure of a
sentence.  It is therefore useful to be able to build up a complex
output data structure piecemeal, combining components according to
information gleaned from computation.

   The program text generation facility allows the user to specify
templates that describe output text fragments (*note Pattern
Specifications: (ptg)Patterns.).  "Holes" in these templates can be
filled with text generated according to other templates.  The result
is a directed, acyclic graph in which each node represents a single
template and the children of that node represent generated text
fragments.  Text at the leaves can be generated by arbitrary
user-supplied routines.  (A library module provides common leaf
generation routines.)

   Eli generates a set of functions, one per template, that are
invoked during computations to build the directed, acyclic graph. 
These functions return values that can be stored as attributes, passed
to text generation functions, and accessed either directly or remotely. 
A distinguished value, `PTGNULL', represents the absence of a graph.

   Printing functions are also provided by Eli to output the generated
text on an arbitrary file (including the standard output unit).  These
functions accept a graph and perform a depth-first, left-to-right
traversal.  The text is output during the traversal, with text
generated by a common subgraph being output once for each parent of
that subgraph.


File: novice,  Node: Specifications,  Next: Products,  Prev: Subproblems,  Up: Overview

Descriptive Mechanisms Known to Eli
===================================

   The Eli user describes the subproblems of a particular text
processing problem.  Eli derives code fragments from these
descriptions, and combines them into a complete program.  Each
description is given in a notation that is ideally suited to the
subproblem being described.

   Subproblem descriptions are placed into files, each of which has a
"type".  The type is indicated by the file name extension: `foo.c' is a
type-`c' file.  Eli recognizes type-`c' and type-`h' files as C
program text and include files respectively.  Here is a list of the
other file types recognized by Eli:

`specs'
     A collection of object names, one per line.

`con'
     A description of the phrase structure of the input text.  Each
     phrase may be associated with a computation to be carried out when
     that phrase is recognized.  Eli generates a parser from these
     specifications.  *Note Syntactic Analysis: (syntax)top.

`gla'
     A description of character sequences, whether they are meaningful
     or not, and what (if any) computation should be carried out when
     they are recognized in the input text.  Eli generates a scanner
     from these specifications.  *Note Lexical Analysis: (lex)top.

`lido'
     A description of the structure of a tree and the computations to
     be carried out on that tree.  Eli generates a tree-walking
     evaluator from these specifications.  For a discussion on
     constructing computations in trees, see *Note LIDO - Computation
     in Trees: (comptrees)top.  For reference, see *Note LIDO -
     Reference Manual: (lidoref)top.

`ctl'
     Constraints on evaluator generation.  Eli uses these
     specifications to modify its behavior when constructing the
     routine that carries out the computations.  *Note LIGA Control
     Language Reference Manual: (lcl)top.

`ptg'
     A description of structured output text.  Eli generates a set of
     output functions from these specifications.  *Note Pattern-Based
     Text Generator: (ptg)top.

`pdl'
     A definition of entities and their associated properties.  Eli
     generates a definition table module from these specifications. 
     *Note PDL Reference Manual: (deftbl)top.

`oil'
     A definition of possible tree node re-labeling.  Eli generates a
     re-labeling module from these specifications.  *Note OIL
     Reference Manual: (oil)top.

`clp'
     A description of the meanings of command line arguments.  Eli
     generates a module that accesses command line arguments from these
     specifications.  *Note CLP Reference Manual: (clp)top.

`map'
     A description of the relationship between the phrase structure of
     the input text and the structure of the tree over which
     computations are to be made.  Eli uses this specification to
     determine the tree building actions that must be attached to
     rules of the parsing grammar.  *Note Mapping: (syntax)Mapping.

`sym'
     This is provided for backward compatibility with previous Eli
     releases for specifying symbolic equivalence classes.  It is
     superseded by type-`map' files.  *Note Specifying symbolic
     equivalence classes: (syntax)Symbol Mapping.

`delit'
     Specifies literals appearing in a type-`con' file that are to be
     recognized by special routines.  Each line of a type-`delit' file
     consists of a regular expression (*note Regular Expressions:
     (lex)Regular Expressions.) optionally followed by an identifier. 
     The regular expression defines the literal to be recognized
     specially.  A `#define' directive making the identifier a synonym
     for that literal's syntax code is placed in the generated file
     `litcode.h'.

`str'
     Specifies initial contents of the identifier table.  Each line of
     a type-`str' file consists of two integers and a sequence of
     characters.  The first integer is the syntax code to be returned
     by `mkidn' (*note Unique Identifier Management:
     (lib)identifier.), and the second is the length of the character
     sequence.  The integer representing the length is terminated by a
     single space.  The character sequence begins immediately after
     this space, and consists of exactly the number of characters
     specified by the length.

`gnrc'
     Defines a generic module.  Generic modules can be instantiated to
     yield collections of specifications that solve specific problems.

`fw'
     Combines a collection of strongly-coupled specifications with
     documentation describing their relationships.  Eli splits these
     specifications according to their types and processes them
     individually.  It can also create a printed document or on-line
     hypertext from a type-`fw' file.

`phi'
     Material to be included in some part of the generated processor. 
     Specification files of this type should have a name consisting of
     three parts: `foo.bar.phi'.  All the files whose names end in
     `bar.phi' are concatenated together in arbitrary order to form a
     file named `bar.h'.  An `#include' directive can then be used to
     incorporate `bar.h' into any generated file.

     `.phi'-file-parts may also be generated by different Eli-Tools.
     They may only be used in files of type `.h' and `.c'. They are
     automatically protected against multiple inclusion.

`eta'
     Material to be included in some part of the specifications.
     Specification files of this type should have a name consisting of
     three parts: `foo.bar.eta'.  All the files whose names end in
     `bar.eta' are concatenated together in arbitrary order to form a
     file named `bar.eta.h'.  An `#include' directive can then be used
     to incorporate `bar.eta.h' in any specification file.

     `.eta'-file-parts can be used in any specification file with the
     exception of `.specs' and `.fw'-files. The generated
     include-files are not protected against multiple inclusion.

Any of these files can contain C-style comments and preprocessor
directives such as `#include', `#define' and `#ifdef'.  The C
preprocessor is applied to files of all types except type-`fw'
*before* those files are examined.  C-style comments and preprocessor
directives appearing in type-`fw' files are passed unchanged to the
files generated from the type-`fw' file.

   Eli includes three pre-defined header files, which are usually
generated from type-`phi' specifications, in specified places:

`HEAD.h'
     Included at the beginning of the main program, the tree
     constructor, and the attribute evaluator.  This header file is
     used primarily to define abstract data types used in tree
     computation.

`INIT.h'
     Included at the beginning of the main program's executable code. 
     `INIT.h' may contain declarations, but only if they appear at the
     beginning of compound statements that lie wholly within `INIT.h'. 
     The content of `INIT.h' will be executed before any other code. 
     Its primary purpose is to initialize abstract data types used in
     tree computation.

`FINL.h'
     Included at the end of the main program's executable code. 
     `FINL.h' may contain declarations, but only if they appear at the
     beginning of compound statements that lie wholly within `FINL.h'. 
     The content of `FINL.h' will be executed after all other code. 
     Its primary purpose is to finalize abstract data types used in
     tree computation.


File: novice,  Node: Products,  Next: Interactive,  Prev: Specifications,  Up: Overview

Common Derived Objects
======================

   Eli recognizes three kinds of object: a "file", a "string" and a
"list".  Examples of files are a specification file such as those
mentioned in the previous section, an executable binary file, or an
output file from a test run.  A flag to a command is an example of a
string.  Lists are ordered sequences of objects, such as the arguments
to a command or the Makefile, C files, and header files that implement
a text processor.

   "Source objects" can be created or modified directly by the user. 
They can be regular files, directories, or symbolic links.  Source
objects cannot be automatically recreated by Eli; they are the basic
building blocks from which Eli creates all other objects.  Every
source object is given a type by Eli based on its host filename, and
this type determines what derived objects can be produced from the
source object.

   The file type of a source file is the longest suffix of the file
name that matches one of the source type suffixes listed in the last
section.  If no suffix match is found, the file type is empty.

   "Derived objects" are objects that can be produced from source
objects and other derived objects through the invocation of one or
more tools.  Tools are invoked only as needed to create a specified
derived object.  Eli automatically caches derived objects for re-use
in future derivations.  Derived objects are created and modified only
by Eli itself, not by users.

   A derived object is named by an "odin-expression" (*note Referring
to Objects: (ui)Objects.).  Lexically, an odin-expression is composed
of a sequence of "identifier" and *operator* tokens, and is terminated
by a newline character.  An odin-expression can be continued on
multiple lines by escaping each newline character with a backslash. 
This backslash (but not the newline) is deleted before the expression
is parsed.  Multiple odin-expressions can be specified on the same line
by separating them with semicolon operators.

   An identifier token is just a sequence of characters.  The
following characters must be escaped to be included in an identifier:

     : + = ( ) / % ; ? $ < > ! # \ ' `space' `tab' `newline'

   A single character can be escaped by preceding it with a backslash
(e.g. `lost\+found').  A sequence of characters can be escaped by
enclosing them in single quote marks (e.g. `'lost+found'').

   Unescaped "white space" characters (spaces, tabs, and newlines) are
ignored during parsing except when they separate adjacent identifiers.

   Here are a number of odin-expressions that name common objects
derived from the same collection of specifications (all of the spaces
are redundant).  The identifier following a colon (`:') is an "object
type" (or "product") that characterizes the properties of the derived
object, while the identifier following a plus (`+') is a "parameter
type" that modifies those properties without changing the nature of
the derived object.  (For the characteristics of all of the products
and parameters defined by Eli, *note Top: (pp)Top..)

`sets.specs :exe'
     is the executable program generated by Eli from the specifications
     enumerated in `sets.specs'.  It is a normal program for the
     machine on which it was generated, and is independent of Eli.

`sets.specs :source'
     is a set of C files, a set of header files, and a Makefile.  The
     result of running `make' with this information is the executable
     program generated by Eli from the specifications enumerated in
     `sets.specs'.

`sets.specs :exe :help'
     is a browser session that helps to explain inconsistencies in the
     specifications enumerated in `sets.specs'.  It provides
     cross-references to on-line documentation and allows you to
     invoke an editor on the proper files to make corrections.

`. +cmd=(sets.specs :exe) (input) :run'
     is the result of running the program generated by Eli from the
     specifications enumerated in `sets.specs' as a command with the
     file `input' from the current directory as an argument.  The name
     of the directory (in this case `.', the name of the current
     directory) in which the program is to be executed precedes the
     parameter that defines the command to be executed.

`sets.specs +monitor +arg=(input) :mon'
     is an interaction with the program generated by Eli from the
     specifications enumerated in `sets.specs', as it processes the
     data file `input'.  This interaction allows you to follow the
     execution at the level of your specifications, rather than at the
     level of the machine on which  the program is running.

`sets.specs +debug :dbx'
     is an interaction with the program generated by Eli from the
     specifications enumerated in `sets.specs' using the symbolic
     debugger of the machine on which the program is running.  It is
     useful when some of your specifications are written directly in C. 
     (Replace `dbx' with `gdb' to use the GNU symbolic debugger.)

`sets.specs :gencode :viewlist'
     is an interactive shell executing in a directory containing all
     text files generated by Eli from the specifications enumerated in
     `sets.specs'.  This facility is sometimes useful in diagnosing
     compiler errors due to type mismatches.

`sets.specs :exe :err >'
     is the raw set of reports generated by inconsistencies in the
     specifications enumerated in `sets.specs', written to the screen. 
     (It would be sent to your editor if you replaced `>' with `<'.)
     This display is sometimes useful if the reports are garbled by the
     `help' derivation.

`sets.specs :exe :warn >'
     is the raw set of reports generated by anomalies in the
     specifications enumerated in `sets.specs', written to the screen. 
     (It would be sent to your editor if you replaced `>' with `<'.)
     This display is sometimes useful if the reports are garbled by the
     `help' derivation.


File: novice,  Node: Interactive,  Next: Escape,  Prev: Products,  Up: Overview

How to Request Product Manufacture
==================================

   Eli is invoked by giving the command `eli'.  If you have never used
Eli before, it will have to establish a "cache" (*note Hints on Cache
Management: Cache.).  This process is signaled by a long sequence of
messages about installing packages, followed by a note that the
packages have been compiled.

   After printing an identifying banner, Eli writes the prompt `->' and
waits for input.  The interactive session can be terminated by
responding to the `->' prompt with a `^D', and you can browse the
documentation by responding with a question mark.

   Entering a derived object name in response to the `->' prompt
constitutes a request to bring that derived object up to date with
respect to all of the source objects on which it depends.  Eli will
carry out the minimum number of operations required to satisfy this
request.  When the next `->' prompt appears, the given object will be
up to date.

   Bringing an object up to date does not yield a copy of that object. 
To obtain a copy, you must add an output request.  The precise form
and effect of an output request depends on whether the object being
output is a file object or a list object.  All source objects are file
objects; to find out the kind of a derived object, consult *Note Top:
(pp)Top.

   Here are some examples of common output requests:

`sets.specs :parsable >'
     requests that the derived file object `sets.specs :parsable' be
     written to the standard output (normally the screen).  Garbage
     will result if the derived object is not a text file.

`sets.specs :exe > trans'
     requests that the derived file object `sets.specs :exe' be
     written to file `trans'.  The derived object must be a file
     object, but it need not be text.  If the file `trans' does not
     exist, it will be created; if it does exist, it will be
     overwritten if its content differs from that of the derived
     object `sets.specs :exe'.  If `trans' exists and is a directory,
     a file named `sets.specs.exe' will be written to that directory
     (*note Extracting and Editing Objects: (ui)copy.).

`sets.specs :source > src'
     requests that the derived list object `sets.specs :source' be
     written to directory `src'.  The directory `src' must exist.  A
     file in `src' before the request will be overwritten only if it
     has the same name as one of the file objects in the list
     `sets.specs :source', but different content.  (Normally, `src'
     would be either an empty directory or one that contains an
     earlier version of `sets.specs :source'.)

`sets.con <'
     requests that your current editor be invoked on the object
     `sets.con'


File: novice,  Node: Escape,  Prev: Interactive,  Up: Overview

How to Invoke Unix Commands
===========================

   While one is interacting with Eli, there are a number of situations
in which one wishes to execute normal operating system commands. 
These commands can be executed with or without derived objects as
arguments.  We have already seen the most general form, a derived
object that is an execution of an arbitrary command in an arbitrary
directory (*note Products::.).  Although this facility is general
enough to handle *any* command execution, it is cumbersome for simple
commands.

   The `!' character introduces a host command line (*note Unix
Commands: (ui)Unix.).  If the first non-white space character
following the `!' is not `:', `;' or `=' then the rest of the line is
treated as a single, escaped sequence of characters.  This avoids the
confusion resulting from interactions between the escape conventions
of host commands and odin-expressions.  A leading `:', `;', `=' or
whitespace can be included in the escaped sequence by preceding it
with `\'.

   If the name of a file object precedes the `!' character, that
object is brought up to date and the name of a file containing it is
appended to the host command line.

   Here are examples of some typical command invocations using `!':

`!ls'
     lists the files in the current directory.

`!mkdir src'
     makes a new subdirectory of the current directory.

`(sets.specs :exe) ! size'
     provides information about the space used by the processor
     generated from `sets.specs'.

`input +cmd=(sets.specs:exe) :stdout ! diff desired'
     compares the file `desired' with the result of applying the
     processor generated from `sets.specs' to the file `input'.


File: novice,  Node: Example,  Next: Strategies,  Prev: Overview,  Up: Top

Example of Eli Use
******************

   The example in this chapter illustrates how text processors are
specified to Eli.  Each section covers a major step in the development
process, discussing the purpose of that step and then carrying it out
for the example.  A set of exercises is provided with each section. 
The purpose of these exercises is to familiarize you with the basic
facilities that Eli provides for dealing with specifications, and how
Eli is typically used.

   All of the text used in the exercises can be obtained, and the
exercises themselves can be carried out, using the facilities of Eli's
system documentation browser described in the first set of exercises
given below (*note Exercises: tskex.).

* Menu:

* Problem::		Statement of the problem to be solved
* Structure::		Specifying the desired phrase structure
* Atoms::		Nonliteral character sequences and comments
* Entities::		Managing source text definitions
* Generation::		Creating structured output text


File: novice,  Node: Problem,  Next: Structure,  Up: Example

Statement of the problem to be solved
=====================================

   You need to classify a collection of several thousand words.  There
are no duplicate words in any class, but a given word may belong to
more than one class.  The classes have arbitrary names, and no two
classes may have the same name.

   A C program will manipulate the words and classes.  Because of the
application, classes will be relatively fluid.  The customer expects
that new words and classes will be added, and the classification of
existing words changed, on the basis of experience and changing
requirements.  Nevertheless, the system design requires that the data
be built into the C program at compile time.

* Menu:

* C::			Data structure required by the C program
* Data::		Proposed notation for describing a classification
* Task::		Description of the translation task
* Exercises: tskex.	Getting the sample specification


File: novice,  Node: C,  Next: Data,  Up: Problem

Data structure required by the C program
........................................

   The system designers have settled on an internal representation of
the data involving an array for each class containing the words in
that class as strings, an array containing the class names as strings,
and an array containing the sizes of the classes as integers.  The
number of classes is also given.  All of these data items are to be
specified in a single header file.  Here is an example of such a
header file for a simple classification:

     int number_of_sets = 3;
     
     char *name_of_set[] = {
     "colors",
     "bugs",
     "verbs"};
     
     int size_of_set[] = {
     3,
     5,
     4};
     
     char *set_of_colors[] = {
     "red",
     "blue",
     "green"};
     
     char *set_of_bugs[] = {
     "ant",
     "spider",
     "fly",
     "moth",
     "bee"};
     
     char *set_of_verbs[] = {
     "crawl",
     "walk",
     "run",
     "fly"};
     
     char **values_of_set[] = {
     set_of_colors,
     set_of_bugs,
     set_of_verbs};


File: novice,  Node: Data,  Next: Task,  Prev: C,  Up: Problem

Proposed notation for describing a classification
.................................................

   Although the meaning of the internal representation is
straightforward, it is quite clear that making the necessary
alterations will be a tedious and error-prone process.  Any change
requires compatible modifications of several arrays.  For example,
moving a word from one class to another means not only cutting and
pasting the word itself, but also changing the sizes of both classes.

   It would be simpler and safer to define the classification with a
notation ideally suited to that task, and generate the header file
from that definition.  Here is an example of an obvious notation,
defining the classification represented by the header file given above:

     colors{red blue green}
     bugs{ant spider fly moth bee}
     verbs{crawl walk run fly}


File: novice,  Node: Task,  Next: tskex,  Prev: Data,  Up: Problem

Description of the translation task
...................................

   The remainder of this chapter discusses the specification and
generation of a program that translates class descriptions into header
files.  This program must accept a class description, verify that
class names are unique and that there is only one occurrence of any
given word in a class, and then write a header file defining the
appropriate data structure.  Its specification is broken into four
parts, each stored in a separate file:

`sets.con'
     A context-free grammar describing the structure of the input text.

`word.gla'
     A specification of the character sequences that are acceptable
     words, and how those character sequences should be represented
     internally, plus a specification of the character sequences to be
     ignored.

`symbol.lido'
     A specification of the context conditions on uniqueness of set
     names and elements within a single set.

`code.fw'
     A specification of the form of the output text and how it is
     constructed.

   File `sets.specs' lists the names of these four files and contains
requests to instantiate three library modules that support them.


File: novice,  Node: tskex,  Prev: Task,  Up: Problem,  Eg: Run

Exercises
---------

   If you are using a computer with multiple-window capability, your
documentation browsing session is independent of your Eli session, so
you can simultaneously browse the documentation and make Eli requests. 
Otherwise you must terminate the document browsing session in order to
make an Eli request.  In that case, you might want to make a note of
your current node (given in the highlighted status line) before
exiting.  When you begin a new session, you can then use the `g'
command to go directly to that node.

  1. Use the documentation browser's `run' command to obtain a copy of
     the complete specification.  You will use this copy to do the
     exercises in the remainder of this chapter.

  2. Verify that you have obtained all of the specification files by
     making the following Unix request via Eli (*note Running Unix
     commands from Eli: (ui)Unix.):

          -> !ls

  3. Examine the file that is not a part of the specification by
     requesting Eli to display it on screen (*note Copying to Standard
     Output: (ui)copying to standard output.):

          -> input>



examples/sets
 

#!/bin/sh
echo 'Obtaining specifications and sample input'
cp $INFOLIB/$INFODIR/[sciw]* .
chmod +w [cwi]*
echo 'Copy complete, hit return to continue'
read answer



File: novice,  Node: Structure,  Next: Atoms,  Prev: Problem,  Up: Example

Specifying the desired phrase structure
=======================================

   The first step in specifying a problem to Eli is to develop a
context-free grammar that describes the phrase structure of the input
text.  This structure must reflect the desired semantics, and it must
be possible for Eli to construct a parser from the grammar.  Grammar
development is a surprisingly difficult task.  It is best to
concentrate on the meaning of the tree structure as you are developing
the grammar, and not try to economize by using the same symbols to
describe constructs that look the same but have different meanings.

* Menu:

* Grammar::		Explanation of the grammar for word classification
* Exercises: parex.	How to verify parsability of a grammar


File: novice,  Node: Grammar,  Next: parex,  Up: Structure

Explanation of the grammar for word classification
..................................................

   One possible description of the structure of the set definition
text is (*note How to describe a context-free grammar:
(syntax)Notation.):

     text: set_defs .
     set_defs: set_def / set_defs set_def .
     set_def: set_name '{' set_body '}' .
     set_name: word .
     set_body: elements .
     elements: set_element / elements set_element .
     set_element: word .

Here each set definition is described as a `set_name' followed by a
bracketed `set_body'.  The text will be made up of an arbitrary number
of such definitions.  A `set_body', in turn, consists of an arbitrary
number of elements.  The `set_name' and each `set_element' is a `word'.

   This structure represents the semantics of the input text: Set
names and set elements have different meanings, even though they are
both written as words.  Set bodies are significant units, even though
they have the same form as any subset of themselves.  The following
specification would *not* reflect the semantics, even though it is
simpler and describes the same input language:

     text: set_defs .
     set_defs: set_def / set_defs set_def .
     set_def: word '{' elements '}' .
     elements: word / elements word .


File: novice,  Node: parex,  Prev: Grammar,  Up: Structure

Exercises
---------

   To get information about whether Eli can construct a parser from a
grammar without actually trying to build the whole program, use the
`:parsable' product (*note parsable: (pp)parsable.).  In order to be
parsable, the grammar must satisfy the "LALR(1) condition".  If the
LALR(1) condition is satisfied, `parsable' will indicate that fact. 
Otherwise it will say that the grammar is not LALR(1) and provide a
listing of conflicts (*note How to Resolve Parsing Conflicts:
(syntax)Conflicts.).

  1. Tell Eli to explain what it is doing, and request verification
     that Eli can generate a parser. Append `>' to the derivation to
     tell Eli to copy the results on the screen.

          -> LogLevel=4
          -> sets.specs :parsable>

        When the process is complete, repeat the last request.  To
     save keystrokes, you can scroll through the "history" (*note The
     History Mechanism: (ui)History.) using the up- and down-arrow
     keys.

        Explain the very different responses to the two requests for
     verification of parsability.

  2. Request an editing session on the file `sets.con' (*note  Editing
     with the Copy Command: (ui)editing with the copy odin-command.):

          -> sets.con<

     Delete `text' from the first rule of the grammar, leaving the
     colon and everything following it unchanged.  Then request
     execution as before, scrolling through the history:

          -> sets.specs:parsable>

        Why was Eli's response so much shorter than before?

  3. Obtain help diagnosing the error you created by deleting `text':

          -> sets.specs :parsable :help

        This request will start a documentation browsing session. 
     Follow the menu to the display for the file in error, and use the
     edit command to gain access to that file.  Correct the error by
     inserting `text' before the colon, exit the editor, and then quit
     the browsing session.  Use the Eli history mechanism to repeat
     the last request:

          -> sets.specs :parsable :help

        Explain Eli's response to this request.  Why was no
     documentation browsing session started?  Why was the response so
     much shorter than the response to the original request for
     derivation and execution of the processor?

  4. Your request for help after fixing the error really didn't
     demonstrate that the grammar was parsable, because it didn't show
     you the result.  Request the result:

          -> sets.specs :parsable>

        Explain Eli's response to this request.  What steps were
     carried out to satisfy it?  Why were these the only ones
     necessary?

  5. Delete the braces { } from the rule defining `set_def' in file
     `sets.con'.  This change makes the entire input text nothing but
     a list of words, with no differentiation between set names and
     elements or between different sets.  Eli will not be able to
     generate a parser from this grammar.  Request verification of
     parsability to see the error report:

          -> sets.specs :parsable >

        A "shift-reduce conflict" is a situation in which the parser
     can't tell whether it should recognize a complete phrase or
     continue to add symbols to an incomplete phrase.  In this
     example, the next word is either the name of a new set (and thus
     the current `elements' phrase is complete), or it is another set
     element (and thus belongs to the current `elements' phrase).

        Add a comma as a separator between set elements, but do not
     re-introduce the braces.  Do you think that Eli will be able to
     generate a parser?  Briefly explain, and then verify your answer. 
     (For a more complete treatment of conflict resolution, see *Note
     How to Resolve Parsing Conflicts: (syntax)Conflicts.)

        Restore the original specification, or change `input' to
     conform to your new specification, to ensure correct behavior for
     later exercises.


File: novice,  Node: Atoms,  Next: Entities,  Prev: Structure,  Up: Example

Nonliteral character sequences and comments
===========================================

   The terminal symbols of the grammar are the literal braces and the
nonliteral symbol `word'.  Eli can easily deduce that the braces are
significant characters, but we must provide a definition of the
significant character sequences that could make up a `word'.  We must
also describe how to capture the significant information in a word for
further processing.

   Eli normally assumes that white space characters (space, tab and
newline) are not significant.  If we want to provide a facility for
commenting a classification then we must additionally define the form
of a comment and specify that character sequences having this form are
also not significant.

* Menu:

* GLA specification::	Explanation of the character sequence description
* Exercises: procex.	How to generate a processor


File: novice,  Node: GLA specification,  Next: procex,  Up: Atoms

Explanation of the character sequence description
.................................................

   Here is one possible description of the non-literal character
sequences and comments:

     word:   $[a-zA-Z]+      [mkidn]
             C_COMMENT

   The first line defines a `word' to be any sequence of one or more
letters (*note Regular Expressions: (lex)Regular expressions.). 
Whenever such a sequence is recognized in the input text, `mkidn' is
invoked to capture the significant information represented by the
sequence.  This processor associates an integer with the recognized
sequence, and arranges for that integer to become the value
representing the character sequence.  If two character sequences
recognized as words are identical, `mkidn' will represent them with
the same integer; distinct sequences are represented by different
integers.

   The second line of the specification does not begin with a symbol
followed by `:', which indicates that the character sequences it
describes are not significant.  It uses a "canned description" to
describe character sequences taking the form of C comments (*note
Canned Symbol Descriptions: (lex)Canned Descriptions.).  Thus any
character sequence taking the form of a C comment will be ignored in
the input text read by the generated program.


File: novice,  Node: procex,  Prev: GLA specification,  Up: Atoms

Exercises
---------

  1. Tell Eli to keep quiet about what it is doing, and then ask it to
     run the processor derived from your specification:

          -> LogLevel=2
          -> input +cmd=(sets.specs :exe) :stdout >

  2. The sample input file does not contain either comments or errors. 
     Introduce an error by inserting a digit into one of the words of
     the example and repeat your request:

          -> input<
          -> input +cmd=(sets.specs :exe) :stdout >

        Briefly explain Eli's response to this request.

  3. Verify that the generated processor correctly handles C comments.

  4. Change the specification to accept only words that begin with
     upper-case letters.  Generate a translator and verify its
     correctness.

  5. Change the specification to allow Ada comments instead of C
     comments.  (Hint: *note Canned Symbol Descriptions: (lex)Canned
     Descriptions..) Generate a translator and verify its correctness.


File: novice,  Node: Entities,  Next: Generation,  Prev: Atoms,  Up: Example

Managing source text definitions
================================

   The statement of the problem requires that the names of the classes
be unique, and that there be only one occurrence of a given word in a
given class.  This sort of condition is very common in translation
problems.  It involves recognition of regions and specific entities
within those regions.  For example, a `set_body' is a region and a
`set_element' is a specific entity within that region.  The check to
be made is that no `set_element' appears more than once in any
`set_body'.

   Regions are defined by the grammar.  Entities may be defined both
by the grammar and by the values representing the terminal symbols:
the grammar selects a particular kind of phrase, while the instances
of this phrase are differentiated by the values of their terminal
symbols.  Some computation must be carried out over the region to
verify the condition.  This computation is standard, involving only
the concepts of region and entity, so a "generic module" can be used
to carry it out.

* Menu:

* Instantiation::	Using generic library modules to test uniqueness
* Exercises: symbex.	How to extract a processor from Eli

